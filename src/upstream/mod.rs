// SPDX-License-Identifier: Apache-2.0

#![allow(unused)]

use crate::DatabaseArgs;
use crate::lang::java::Java;
use crate::lang::{Dialect, LanguageDefinition};
use crate::upstream::matched::UpstreamMatch;
use crate::upstream::matcher::{Extractor, Matcher};
use anyhow::{Context, Error, bail};
use clap::Args;
use gix::bstr::{ByteSlice, ByteVec};
use gix::traverse::tree::Recorder;
use gix::traverse::tree::recorder::Entry;
use gix::{Repository, ThreadSafeRepository};
use gix_glob::Pattern;
use gix_glob::wildmatch::Mode;
use regex::Regex;
use sha2::{Digest, Sha256};
use std::path::{Path, PathBuf};
use std::sync::{Arc, LazyLock};
use streaming_iterator::StreamingIterator;
use tokio::fs;
use tokio::task::JoinSet;
use tracing::{debug, trace};
use tree_sitter::{Language, Parser, Point, QueryCursor, Range};
use url::Url;
use walkdir::{DirEntry, WalkDir};

pub mod matched;
pub mod matcher;

pub type UpstreamId = String;

#[derive(Args, Clone, Debug)]
pub struct UpstreamScanArgs {
    #[command(flatten)]
    pub database: DatabaseArgs,

    /// Path to upstream Git Repository
    pub repo_path: PathBuf,

    /// Git branch or hash to scan
    pub revision: String,
}

pub struct Upstream {
    /// Unique ID for upstream
    pub id: UpstreamId,

    /// Human-friendly name of upstream
    pub name: String,

    /// Path to upstream git repository.
    ///
    /// This can be relative or absolute to suit your environment.
    pub path: PathBuf,

    /// Link to the repository for display purposes
    pub repo: Option<Url>,

    /// List of source directories within this upstream
    pub roots: Vec<SourceRoot>,

    /// Optional human-friendly notes for this upstream
    pub notes: Option<String>,
}

impl Upstream {
    /// Collect all matched items for the given upstream configuration
    pub async fn scan(&self, revision: &str) -> anyhow::Result<Vec<UpstreamMatch>> {
        if !self.path.exists() {
            bail!("Could not find repository root at {}", self.path.display());
        }

        let mut matched_items = Vec::new();
        for root in &self.roots {
            let mut matches = root.scan(self, revision).await?;
            matched_items.append(&mut matches);
        }
        Ok(matched_items)
    }
}

/// Describes a source tree within an upstream repository.
pub struct SourceRoot {
    /// ID for source root, unique within the upstream.
    pub id: String,

    /// Human-friendly name for source root
    pub name: String,

    /// Language and matchers used within this source root
    pub dialect: Arc<Dialect>,

    /// Optional human-friendly notes for this language
    pub notes: Option<String>,

    /// List of globs matching files that are eligible for processing with the
    /// language's matchers. This list is pruned by the excludes list.
    pub includes: Vec<(Pattern, Mode)>,

    /// List of globs that prune file list generated by the includes.
    pub excludes: Vec<(Pattern, Mode)>,
}

impl SourceRoot {
    pub async fn scan(
        &self,
        upstream: &Upstream,
        revision: &str,
    ) -> anyhow::Result<Vec<UpstreamMatch>> {
        let mut matched_items = Vec::new();

        let repo_path = upstream.path.clone();
        let repo_sync = gix::open(&repo_path)
            .with_context(|| format!("Open git repo at {}", &repo_path.display()))?
            .into_sync();

        let repo = repo_sync.clone().to_thread_local();
        let rev = repo
            .rev_parse_single(revision)
            .with_context(|| format!("Get revision for {revision}"))?;
        let tree = rev
            .object()
            .context("Object must exist for known-good revision")?
            .peel_to_tree()
            .context("Get tree for revision object")?;

        // Process file tree
        let mut recorder = Recorder::default();
        tree.traverse()
            .breadthfirst(&mut recorder)
            .with_context(|| format!("Enumerate all items in tree at revision {revision})"))?;

        let entries: Vec<Entry> = recorder
            .records
            .into_iter()
            // TODO symlink handling with .is_blob_or_symlink()
            .filter(|entry| entry.mode.is_blob())
            .collect();

        println!(
            "Filtering {} entries in repo at revision {} ({})",
            entries.len(),
            revision,
            rev.to_hex()
        );

        // Process file entry.
        let mut set = JoinSet::new();
        for entry in entries {
            // Upstream include/exclude filters
            if !self
                .includes
                .iter()
                .any(|(pat, mode)| pat.matches(entry.filepath.as_ref(), *mode))
            {
                continue;
            };
            if self
                .excludes
                .iter()
                .any(|(pat, mode)| pat.matches(entry.filepath.as_ref(), *mode))
            {
                continue;
            }

            let dialect = Arc::clone(&self.dialect);

            if !self
                .dialect
                .should_match
                .is_some_and(|f| f(&entry.filepath))
            {
                continue;
            }

            // Language-level path filter has a final veto

            let repo = repo_sync.clone();
            let upstream_id = upstream.id.clone();
            let revision = revision.to_string();

            set.spawn(async move {
                process_file_entry(&upstream_id, dialect, &repo, &revision, &entry)
            });
        }

        let results = set
            .join_all()
            .await
            .into_iter()
            .collect::<anyhow::Result<Vec<Vec<UpstreamMatch>>>>()?
            .into_iter()
            .flatten()
            .collect::<Vec<UpstreamMatch>>();
        println!("Found {} results", results.len());

        Ok(matched_items)
    }
}

// DESIGN Is there a way to replace runs of multiple spaces without resorting to regex?
/// Match all instances of multiple spaces
static IDENT_CLEANUP: LazyLock<Regex> =
    LazyLock::new(|| Regex::new(r#"(?m)\s+"#).expect("Ident cleanup regex must be valid"));

/// Parse file and use matchers to extract items of interest.
fn process_file_entry(
    upstream_id: &str,
    dialect: Arc<Dialect>,
    repo: &ThreadSafeRepository,
    revision: &str,
    entry: &Entry,
) -> anyhow::Result<Vec<UpstreamMatch>> {
    let repo = repo.to_thread_local();
    let mut results = Vec::new();

    // Set up parser
    let mut parser = Parser::new();
    parser.set_language(&dialect.language)?;

    // Get data from repo blob
    let file_blob = repo
        .find_blob(entry.oid)
        .context("Get blob for file data")?;
    let data = &file_blob.data;

    // Parse tree and extract matches
    let tree = parser.parse(data, None).context("Parse source file")?;
    for matcher in &dialect.matchers {
        let mut cursor = QueryCursor::new();
        let query = &matcher.query;

        let mut matches = cursor.matches(&query, tree.root_node(), data.as_slice());

        while let Some(matched) = matches.next() {
            if matched.captures.is_empty() {
                continue;
            }

            // Build outer range for match.
            let mut range = Range {
                start_byte: usize::MAX,
                end_byte: usize::MIN,
                start_point: Point::default(),
                end_point: Point::default(),
            };
            for cap in matched.captures {
                // Find the lowest start point
                if cap.node.start_byte() <= range.start_byte {
                    range.start_byte = cap.node.start_byte();
                    range.start_point = cap.node.start_position();
                }
                // Find the highest endpoint
                if cap.node.end_byte() >= range.end_byte {
                    range.end_byte = cap.node.end_byte();
                    range.end_point = cap.node.end_position();
                }
            }

            // Extract full body of match and compute checksum
            let body_checksum = Extractor::checksum_whole_match::<Sha256>(matched, data)?;
            let file = entry.filepath.to_path_lossy().to_path_buf();

            // Extract ident from the match body
            let identifier = matcher
                .ident
                .as_ref()
                .map(|m| m.extract(matched, data))
                .transpose()?
                .map(|ident| ident.into_string_lossy())
                .map(|ident| ident.replace("\\n", ""))
                .map(|ident| IDENT_CLEANUP.replace_all(&ident, " ").trim().to_owned())
                .unwrap_or("(no ident)".to_string());

            trace!(
                checksum = format!("{:02x}", body_checksum),
                file = entry.filepath.to_string(),
                kind = matcher.kind,
                ident = identifier,
                "Matched item"
            );

            // Build and return match
            let upstream_match = UpstreamMatch {
                upstream: upstream_id.to_string(),
                revision: revision.to_string(),
                file,
                range,
                lang: dialect.name.to_string(),
                kind: matcher.kind.to_string(),
                identifier,
                hash_algorithm: "sha256".to_string(),
                hash: body_checksum.to_vec(),
                hash_stripped: None,
                notes: None,
            };

            results.push(upstream_match);
        }
    }
    Ok(results)
}

/// Perform a scan with a hard-coded upstream
#[tokio::test]
async fn test_scan() -> anyhow::Result<()> {
    let cwd = std::env::current_dir()?;
    println!("{:?}", cwd);

    let upstream = Upstream {
        id: "self-test".to_string(),
        name: "Internal Tests".to_string(),
        path: PathBuf::from("./"),
        repo: None,
        roots: vec![SourceRoot {
            id: "java".into(),
            name: "Java".into(),
            dialect: Arc::new(Java {}.configuration()?),
            notes: None,
            includes: vec![(
                gix_glob::parse("tests/**/*.java").context("Glob should parse")?,
                Mode::NO_MATCH_SLASH_LITERAL,
            )],
            excludes: vec![],
        }],
        notes: None,
    };

    let results = upstream.scan("main").await?;
    println!("Found {} results", results.len());
    dbg!(&results);

    Ok(())
}

#[tokio::test]
async fn test_scan_sdfs() -> anyhow::Result<()> {
    let cwd = std::env::current_dir()?;
    println!("{:?}", cwd);

    let upstream = Upstream {
        id: "self-test".to_string(),
        name: "Internal Tests".to_string(),
        path: PathBuf::from("../../OSS/sdfs"),
        repo: None,
        roots: vec![SourceRoot {
            id: "java".into(),
            name: "Java".into(),
            dialect: Arc::new(Java {}.configuration()?),
            notes: None,
            includes: vec![(
                gix_glob::parse("src/**/*.java").context("Glob should parse")?,
                Mode::NO_MATCH_SLASH_LITERAL,
            )],
            excludes: vec![],
        }],
        notes: None,
    };

    let results = upstream.scan("master").await?;
    println!("Found {} results", results.len());
    dbg!(&results);

    Ok(())
}

#[tokio::test]
async fn test_scan_cassandra() -> anyhow::Result<()> {
    let cwd = std::env::current_dir()?;
    println!("{:?}", cwd);

    let upstream = Upstream {
        id: "self-test".to_string(),
        name: "Internal Tests".to_string(),
        path: PathBuf::from("../../OSS/cassandra"),
        repo: None,
        roots: vec![SourceRoot {
            id: "java".into(),
            name: "Java".into(),
            dialect: Arc::new(Java {}.configuration()?),
            notes: None,
            includes: vec![(
                gix_glob::parse("src/**/*.java").context("Glob should parse")?,
                Mode::NO_MATCH_SLASH_LITERAL,
            )],
            excludes: vec![],
        }],
        notes: None,
    };

    let results = upstream.scan("trunk").await?;
    println!("Found {} results", results.len());
    dbg!(&results);

    Ok(())
}
